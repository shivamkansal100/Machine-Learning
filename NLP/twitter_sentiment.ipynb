{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"train_twitter.csv\",delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tweet_id                      0\n",
       "airline_sentiment             0\n",
       "airline                       0\n",
       "airline_sentiment_gold    10949\n",
       "name                          0\n",
       "negativereason_gold       10956\n",
       "retweet_count                 0\n",
       "text                          0\n",
       "tweet_coord               10204\n",
       "tweet_created                 0\n",
       "tweet_location             3550\n",
       "user_timezone              3577\n",
       "dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>airline</th>\n",
       "      <th>airline_sentiment_gold</th>\n",
       "      <th>name</th>\n",
       "      <th>negativereason_gold</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>text</th>\n",
       "      <th>tweet_coord</th>\n",
       "      <th>tweet_created</th>\n",
       "      <th>tweet_location</th>\n",
       "      <th>user_timezone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>569682010270101504</td>\n",
       "      <td>American</td>\n",
       "      <td>NaN</td>\n",
       "      <td>zsalim03</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@AmericanAir In car gng to DFW. Pulled over 1h...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-22 18:15:50 -0800</td>\n",
       "      <td>Texas</td>\n",
       "      <td>Central Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>569608307184242688</td>\n",
       "      <td>American</td>\n",
       "      <td>NaN</td>\n",
       "      <td>sa_craig</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@AmericanAir after all, the plane didn’t land ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-22 13:22:57 -0800</td>\n",
       "      <td>College Station, TX</td>\n",
       "      <td>Central Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>567879304593408001</td>\n",
       "      <td>Southwest</td>\n",
       "      <td>NaN</td>\n",
       "      <td>DanaChristos</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>@SouthwestAir can't believe how many paying cu...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-17 18:52:31 -0800</td>\n",
       "      <td>CT</td>\n",
       "      <td>Eastern Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>569757651539660801</td>\n",
       "      <td>US Airways</td>\n",
       "      <td>NaN</td>\n",
       "      <td>rossj987</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@USAirways I can legitimately say that I would...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-22 23:16:24 -0800</td>\n",
       "      <td>Washington, D.C.</td>\n",
       "      <td>Eastern Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>569900705852608513</td>\n",
       "      <td>American</td>\n",
       "      <td>NaN</td>\n",
       "      <td>tranpham18</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@AmericanAir still no response from AA. great ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-23 08:44:51 -0800</td>\n",
       "      <td>New York City</td>\n",
       "      <td>Eastern Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             tweet_id     airline airline_sentiment_gold          name  \\\n",
       "0  569682010270101504    American                    NaN      zsalim03   \n",
       "1  569608307184242688    American                    NaN      sa_craig   \n",
       "2  567879304593408001   Southwest                    NaN  DanaChristos   \n",
       "3  569757651539660801  US Airways                    NaN      rossj987   \n",
       "4  569900705852608513    American                    NaN    tranpham18   \n",
       "\n",
       "  negativereason_gold  retweet_count  \\\n",
       "0                 NaN              0   \n",
       "1                 NaN              0   \n",
       "2                 NaN              1   \n",
       "3                 NaN              0   \n",
       "4                 NaN              0   \n",
       "\n",
       "                                                text tweet_coord  \\\n",
       "0  @AmericanAir In car gng to DFW. Pulled over 1h...         NaN   \n",
       "1  @AmericanAir after all, the plane didn’t land ...         NaN   \n",
       "2  @SouthwestAir can't believe how many paying cu...         NaN   \n",
       "3  @USAirways I can legitimately say that I would...         NaN   \n",
       "4  @AmericanAir still no response from AA. great ...         NaN   \n",
       "\n",
       "               tweet_created       tweet_location               user_timezone  \n",
       "0  2015-02-22 18:15:50 -0800                Texas  Central Time (US & Canada)  \n",
       "1  2015-02-22 13:22:57 -0800  College Station, TX  Central Time (US & Canada)  \n",
       "2  2015-02-17 18:52:31 -0800                   CT  Eastern Time (US & Canada)  \n",
       "3  2015-02-22 23:16:24 -0800     Washington, D.C.  Eastern Time (US & Canada)  \n",
       "4  2015-02-23 08:44:51 -0800        New York City  Eastern Time (US & Canada)  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = pd.read_csv(\"test_twitter.csv\",delimiter=',')\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleaning the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#removing all the columns with many NAs\n",
    "del train[\"airline_sentiment_gold\"]\n",
    "del train[\"negativereason_gold\"]\n",
    "del train[\"tweet_coord\"]\n",
    "del train[\"tweet_location\"]\n",
    "del train[\"user_timezone\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>airline_sentiment</th>\n",
       "      <th>airline</th>\n",
       "      <th>name</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>text</th>\n",
       "      <th>tweet_created</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>567900433542488064</td>\n",
       "      <td>negative</td>\n",
       "      <td>Southwest</td>\n",
       "      <td>ColeyGirouard</td>\n",
       "      <td>0</td>\n",
       "      <td>@SouthwestAir I am scheduled for the morning, ...</td>\n",
       "      <td>2015-02-17 20:16:29 -0800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>569989168903819264</td>\n",
       "      <td>positive</td>\n",
       "      <td>Southwest</td>\n",
       "      <td>WalterFaddoul</td>\n",
       "      <td>0</td>\n",
       "      <td>@SouthwestAir seeing your workers time in and ...</td>\n",
       "      <td>2015-02-23 14:36:22 -0800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>568089179520954368</td>\n",
       "      <td>positive</td>\n",
       "      <td>United</td>\n",
       "      <td>LocalKyle</td>\n",
       "      <td>0</td>\n",
       "      <td>@united Flew ORD to Miami and back and  had gr...</td>\n",
       "      <td>2015-02-18 08:46:29 -0800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>568928195581513728</td>\n",
       "      <td>negative</td>\n",
       "      <td>Southwest</td>\n",
       "      <td>amccarthy19</td>\n",
       "      <td>0</td>\n",
       "      <td>@SouthwestAir @dultch97 that's horse radish 😤🐴</td>\n",
       "      <td>2015-02-20 16:20:26 -0800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>568594180014014464</td>\n",
       "      <td>negative</td>\n",
       "      <td>United</td>\n",
       "      <td>J_Okayy</td>\n",
       "      <td>0</td>\n",
       "      <td>@united so our flight into ORD was delayed bec...</td>\n",
       "      <td>2015-02-19 18:13:11 -0800</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             tweet_id airline_sentiment    airline           name  \\\n",
       "0  567900433542488064          negative  Southwest  ColeyGirouard   \n",
       "1  569989168903819264          positive  Southwest  WalterFaddoul   \n",
       "2  568089179520954368          positive     United      LocalKyle   \n",
       "3  568928195581513728          negative  Southwest    amccarthy19   \n",
       "4  568594180014014464          negative     United        J_Okayy   \n",
       "\n",
       "   retweet_count                                               text  \\\n",
       "0              0  @SouthwestAir I am scheduled for the morning, ...   \n",
       "1              0  @SouthwestAir seeing your workers time in and ...   \n",
       "2              0  @united Flew ORD to Miami and back and  had gr...   \n",
       "3              0     @SouthwestAir @dultch97 that's horse radish 😤🐴   \n",
       "4              0  @united so our flight into ORD was delayed bec...   \n",
       "\n",
       "               tweet_created  \n",
       "0  2015-02-17 20:16:29 -0800  \n",
       "1  2015-02-23 14:36:22 -0800  \n",
       "2  2015-02-18 08:46:29 -0800  \n",
       "3  2015-02-20 16:20:26 -0800  \n",
       "4  2015-02-19 18:13:11 -0800  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#removing the redundant data\n",
    "#like tweet_id, airline, tweet created, retweet count, name.\n",
    "#they are not important to determine the sentiments\n",
    "del train[\"tweet_id\"]\n",
    "del train[\"airline\"]\n",
    "del train[\"tweet_created\"]\n",
    "del train[\"name\"]\n",
    "del train[\"retweet_count\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_doc = train[\"text\"].values\n",
    "test_doc = test[\"text\"].values\n",
    "train_result = train[\"airline_sentiment\"].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleaning the text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "211"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "stops = set(stopwords.words('english'))\n",
    "import string\n",
    "punc = list(string.punctuation)\n",
    "stops.update(punc)\n",
    "len(stops)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import wordnet\n",
    "def get_simple_pos(tag):\n",
    "    \n",
    "    if tag.startswith('J'):\n",
    "        return wordnet.ADJ\n",
    "    elif tag.startswith('V'):\n",
    "        return wordnet.VERB\n",
    "    elif tag.startswith('N'):\n",
    "        return wordnet.NOUN\n",
    "    elif tag.startswith('R'):\n",
    "        return wordnet.ADV\n",
    "    else:\n",
    "        return wordnet.NOUN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import pos_tag\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "lemmatizer = WordNetLemmatizer()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    words = word_tokenize(text)\n",
    "    output = []\n",
    "    for w in words:\n",
    "        if w.lower() not in stops:\n",
    "            pos = pos_tag(w)\n",
    "            clean_word = lemmatizer.lemmatize(w.lower(),get_simple_pos(pos[0][1]))\n",
    "            output.append(clean_word)\n",
    "    cleaned_review = \" \".join(output)\n",
    "    return cleaned_review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'southwestair scheduled morning 2 days fact yes..not sure evening flight one cancel flightled'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xtrain = [clean_text(train_doc[i]) for i in range(len(train_doc))]\n",
    "xtrain[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['southwestair scheduled morning 2 days fact yes..not sure evening flight one cancel flightled',\n",
       " 'southwestair seeing worker time time going beyond love flying guy thank',\n",
       " 'united flew ord miami back great crew service leg thanks',\n",
       " \"southwestair dultch97 's horse radish 😤🐴\",\n",
       " 'united flight ord delayed air force one last flight sbn 8:20 5 min landed']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xtrain[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#removing emojis from the text\n",
    "import emoji\n",
    "def give_emoji_free_text(text):\n",
    "    allchars = [str for str in text]\n",
    "    emoji_list = [c for c in allchars if c in emoji.UNICODE_EMOJI]\n",
    "    clean_text = ' '.join([str for str in text.split() if not any(i in str for i in emoji_list)])\n",
    "\n",
    "    return clean_text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['southwestair scheduled morning 2 days fact yes..not sure evening flight one cancel flightled',\n",
       " 'southwestair seeing worker time time going beyond love flying guy thank',\n",
       " 'united flew ord miami back great crew service leg thanks',\n",
       " \"southwestair dultch97 's horse radish\",\n",
       " 'united flight ord delayed air force one last flight sbn 8:20 5 min landed']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xtrain = [give_emoji_free_text(xtrain[i]) for i in range(len(xtrain))]\n",
    "xtrain[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Working on the text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "#count_vec = CountVectorizer(max_features = 1000,max_df=0.95,min_df=0.05)\n",
    "#count_vec = CountVectorizer(max_features = 1000)\n",
    "count_vec = CountVectorizer(max_features = 1000,max_df=0.98,min_df=0.03,ngram_range=(1,3))\n",
    "#count_vec = CountVectorizer(max_features = 2000,ngram_range=(1,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<10980x44 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 33365 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_features = count_vec.fit_transform(xtrain)\n",
    "x_train_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "xtrain_sample,xtest_sample,ytrain_sample,ytest_sample = train_test_split(xtrain,train_result,random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=None, error_score='raise',\n",
       "       estimator=SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False),\n",
       "       fit_params=None, iid=True, n_jobs=1,\n",
       "       param_grid={'C': [100.0, 1000.0, 5000.0, 10000.0, 50000.0, 100000.0], 'gamma': [0.001, 0.0005, 0.0001, 0.005]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "svc = SVC()\n",
    "grid = {'C' : [1e2, 1e3, 5e3, 1e4, 5e4, 1e5],\n",
    "       'gamma' : [1e-3, 5e-4, 1e-4, 5e-3]}\n",
    "abc = GridSearchCV(svc, grid)\n",
    "abc.fit(x_train_features, train_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=50000.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma=0.001, kernel='rbf',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "abc.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"americanair car gng dfw pulled 1hr ago icy road on-hold aa since 1hr ca n't reach arpt aa2450 wat 2\",\n",
       " 'americanair plane ’ land identical worse condition grk according metars',\n",
       " \"southwestair ca n't believe many pay customer left high dry reason flight cancel flightlations monday bdl wow\",\n",
       " 'usairways legitimately say would rather driven cross country flown u airway',\n",
       " 'americanair still response aa great job guy']"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xtest = [clean_text(test_doc[i]) for i in range(len(test_doc))]\n",
    "xtest[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"americanair car gng dfw pulled 1hr ago icy road on-hold aa since 1hr ca n't reach arpt aa2450 wat 2\",\n",
       " 'americanair plane ’ land identical worse condition grk according metars',\n",
       " \"southwestair ca n't believe many pay customer left high dry reason flight cancel flightlations monday bdl wow\",\n",
       " 'usairways legitimately say would rather driven cross country flown u airway',\n",
       " 'americanair still response aa great job guy']"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xtest = [give_emoji_free_text(xtest[i]) for i in range(len(xtest))]\n",
    "xtest[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<3660x44 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 11044 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test_features = count_vec.transform(xtest)\n",
    "x_test_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=100, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma=0.008, kernel='rbf',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "svc = SVC(C=100,gamma=0.008)\n",
    "svc.fit(x_train_features,train_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = svc.predict(x_test_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt(\"pred.csv\",y_pred,delimiter=',',fmt='%s')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
